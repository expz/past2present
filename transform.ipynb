{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import benepar\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(BeneparComponent(\"benepar_en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(['The cat ate the hat.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "The cat ate the hat.\n",
      "[The cat, ate the hat, .]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    doc = nlp.get_pipe('benepar')(doc)\n",
    "    for sent in doc.sents:\n",
    "        print('-----')\n",
    "        print(sent.text)\n",
    "        print(list(sent._.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<benepar.spacy_plugin.BeneparComponent at 0x7fea117387b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe('benepar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(sent_text):\n",
    "    doc = nlp(sent_text, disable=['ner', 'textcat'])\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, list(token.children))\n",
    "    sent = list(doc.sents)[0]\n",
    "    print(sent._.parse_string)\n",
    "    print(list(sent._.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det []\n",
      "black black ADJ JJ amod []\n",
      "goat goat NOUN NN ROOT [The, black, eating, .]\n",
      "who who NOUN WP nsubj []\n",
      "had have VERB VBD aux []\n",
      "been be VERB VBN aux []\n",
      "eating eat VERB VBG relcl [who, had, been, slept]\n",
      "since since ADP IN mark []\n",
      "the the DET DT det []\n",
      "morning morning NOUN NN nsubj [the]\n",
      "slept sleep VERB VBD advcl [since, morning, in]\n",
      "in in ADP IN prep [grass]\n",
      "the the DET DT det []\n",
      "grass grass NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (NP (DT The) (JJ black) (NN goat)) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN been) (VP (VBG eating) (PP (IN since) (NP (DT the) (NN morning))))))))) (VP (VBD slept) (PP (IN in) (NP (DT the) (NN grass)))) (. .))\n",
      "[The black goat who had been eating since the morning, slept in the grass, .]\n",
      "He -PRON- PRON PRP nsubj []\n",
      "had have VERB VBD aux []\n",
      "arranged arrange VERB VBN ROOT [He, had, steer, .]\n",
      "that that ADP IN mark []\n",
      "the the DET DT det []\n",
      "skipper skipper NOUN NN nsubj [the]\n",
      "should should VERB MD aux []\n",
      "steer steer VERB VB ccomp [that, skipper, should]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (PRP He)) (VP (VBD had) (VP (VBN arranged) (SBAR (IN that) (S (NP (DT the) (NN skipper)) (VP (MD should) (VP (VB steer))))))) (. .))\n",
      "[He, had arranged that the skipper should steer, .]\n",
      "He -PRON- PRON PRP nsubj [and, goat]\n",
      "and and CCONJ CC cc []\n",
      "the the DET DT det []\n",
      "white white ADJ JJ amod []\n",
      "goat goat NOUN NN conj [the, white, ate]\n",
      "that that ADJ WDT nsubj []\n",
      "ate eat VERB VBD relcl [that, cheese]\n",
      "the the DET DT det []\n",
      "cheese cheese NOUN NN dobj [the]\n",
      "went go VERB VBD ROOT [He, to, .]\n",
      "to to ADP IN prep [store]\n",
      "the the DET DT det []\n",
      "store store NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (NP (PRP He)) (CC and) (NP (NP (DT the) (JJ white) (NN goat)) (SBAR (WHNP (WDT that)) (S (VP (VBD ate) (NP (DT the) (NN cheese))))))) (VP (VBD went) (PP (IN to) (NP (DT the) (NN store)))) (. .))\n",
      "[He and the white goat that ate the cheese, went to the store, .]\n"
     ]
    }
   ],
   "source": [
    "parse('The black goat who had been eating since the morning slept in the grass.')\n",
    "parse('He had arranged that the skipper should steer.')\n",
    "parse('He and the white goat that ate the cheese went to the store.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from pattern.en import conjugate\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These must match the conjugations of the `pattern` package.\n",
    "PAST_CONJ = {\n",
    "    '1sg': '1sgp',\n",
    "    '2sg': '2sgp',\n",
    "    '3sg': '3sgp',\n",
    "    'pl': 'ppl',\n",
    "    'part': 'ppart',\n",
    "}\n",
    "\n",
    "def contains_one_of(haystack, needles):\n",
    "    for item in haystack:\n",
    "        for needle in needles:\n",
    "            if item == needle:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def conj_to_past(number_person):\n",
    "    return PAST_CONJ.get(number_person, None)\n",
    "\n",
    "def is_past(tok, number_person=None):\n",
    "    \"\"\"\n",
    "    Is `verb` past tense, where `verb` has lemma `lemma`\n",
    "    and number/person `number_person`?\n",
    "    \"\"\"\n",
    "    if tok.tag_ == 'VBN' or tok.tag_ == 'VBD':\n",
    "        return True\n",
    "    if number_person:\n",
    "        return conjugate(tok.lemma_, conj_to_past(number_person)) == tok.text\n",
    "    return (\n",
    "        conjugate(tok.lemma_, '1sgp') == tok.text\n",
    "        or conjugate(tok.lemma_, '2sgp') == tok.text\n",
    "        or conjugate(tok.lemma_, '3sgp') == tok.text\n",
    "    )\n",
    "\n",
    "def is_participle(span):\n",
    "    \"\"\"\n",
    "    Expects a span of length one.\n",
    "    \"\"\"\n",
    "    return contains_one_of(span._.labels, ('VBG', 'VBN'))\n",
    "\n",
    "def find_nsubj(np):\n",
    "    \"\"\"\n",
    "    Expects a span with label NP.\n",
    "    \"\"\"\n",
    "    nsubj = None\n",
    "    s = []\n",
    "    s.append(np)\n",
    "    while s:\n",
    "        span = s.pop()\n",
    "        if len(span) == 1 and (span[0].dep_ == 'nsubj' or span[0].dep_ == 'nsubjpass'):\n",
    "            nsubj = span\n",
    "        elif contains_one_of(span._.labels, ('S', 'ADVP', 'PP', 'ADJP', 'PRN', 'QP', 'RRC', 'X')):\n",
    "            continue\n",
    "        s.extend(span._.children)\n",
    "    return nsubj\n",
    "\n",
    "def number_person(token):\n",
    "    \"\"\"\n",
    "    Expects a token with POS == 'NOUN'.\n",
    "    \"\"\"\n",
    "    for tok in token.children:\n",
    "        if tok.lower_ == 'and':\n",
    "            return 'pl'\n",
    "    if token.tag_ == 'NNPS' or token.tag_ == 'NNS' or token.lower_ == 'we' or token.lower_ == 'they':\n",
    "        return 'pl'\n",
    "    elif token.lower_ == 'i':\n",
    "        return '1sg'\n",
    "    elif token.lower_ == 'you':\n",
    "        return '2sg'\n",
    "    else:\n",
    "        return '3sg'\n",
    "\n",
    "def object_to_subject(np):\n",
    "    subject = ''\n",
    "    s = [np]\n",
    "    while s:\n",
    "        span = s.pop()\n",
    "        if len(span) == 1 and span[0].tag_ == 'PRP':\n",
    "            if span.text == 'him':\n",
    "                subject += 'he' + span[0].whitespace_\n",
    "            elif span.text == 'her':\n",
    "                subject += 'she' + span[0].whitespace_\n",
    "            elif span.text == 'them':\n",
    "                subject += 'they' + span[0].whitespace_\n",
    "            else:\n",
    "                subject += span.text_with_ws\n",
    "        elif contains_one_of(span._.labels, ('S', 'ADVP', 'PP', 'ADJP', 'PRN', 'QP', 'RRC', 'X')):\n",
    "            continue\n",
    "        elif len(span) == 1:\n",
    "            subject += span.text_with_ws\n",
    "        s.extend(reversed(list(span._.children)))\n",
    "    return subject.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import conjugate\n",
    "\n",
    "def present_to_past(token):\n",
    "    txt = token.text.lower()\n",
    "    if conjugate(token.lemma_, '1sg') == txt:\n",
    "        return conjugate(token.lemma_, '1sgp')\n",
    "    elif conjugate(token.lemma_, '2sg') == txt:\n",
    "        return conjugate(token.lemma_, '2sgp')\n",
    "    elif conjugate(token.lemma_, '3sg') == txt:\n",
    "        return conjugate(token.lemma_, '3sgp')\n",
    "    elif conjugate(token.lemma_, 'pl') == txt:\n",
    "        return conjugate(token.lemma_, 'ppl')\n",
    "    elif conjugate(token.lemma_, 'part') == txt:\n",
    "        return conjugate(token.lemma_, 'ppart')\n",
    "    else:\n",
    "        return token.text\n",
    "\n",
    "def transform_past(sent_text):\n",
    "    doc = nlp(sent_text)\n",
    "    trans_text = []\n",
    "    for sent in doc.sents:\n",
    "        trans_text.append(transform_past_span(sent))\n",
    "    return ' '.join(trans_text)\n",
    "\n",
    "def transform_past_span(sent):\n",
    "    tr_doc = []\n",
    "    for tok in sent:\n",
    "        if tok.tag_ == 'VBZ' or tok.tag_ == 'VBP':\n",
    "            if tok.dep_ == 'aux':\n",
    "                if tok.lemma_ == 'do':\n",
    "                    # present emphatic\n",
    "                    tr_doc.append('did')\n",
    "                elif tok.lemma_ == 'be':\n",
    "                    # present progressive\n",
    "                    tr_doc.append(present_to_past(tok))\n",
    "            else:\n",
    "                # present\n",
    "                tr_doc.append(present_to_past(tok))\n",
    "        else:\n",
    "            tr_doc.append(tok.text)\n",
    "    return ' '.join(tr_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_present(text, echo=False):\n",
    "    \"\"\"\n",
    "    It is not allowed to have sentences that conjunct verbs of different tenses\n",
    "    without auxiliary verbs:\n",
    "    \n",
    "    * \"We will go tomorrow and go today.\"\n",
    "    \n",
    "    This is because they are ambiguous without knowledge of adverbs like \"tomorrow\"\n",
    "    and \"today\":\n",
    "    \n",
    "    \"We will go and eat.\"\n",
    "    \n",
    "    Should eat be present or future tense? We assume future to avoid having to\n",
    "    analyze the semantics of adverbial phrases.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    trans_text = []\n",
    "    for sent in doc.sents:\n",
    "        trans_text.append(Sentence(sent).transform_present())\n",
    "        if echo:\n",
    "            print(trans_text[-1])\n",
    "    return ' '.join(trans_text)\n",
    "\n",
    "class Verb(object):\n",
    "    \"\"\"\n",
    "    This class if for those verbs which have the following dependency labels:\n",
    "    \n",
    "    VERB ROOT\n",
    "    WHNP > WDT --relcl--> NN\n",
    "    VERB --advcl--> NN\n",
    "    VERB --advcl--> IN\n",
    "    VERB --ccomp--> NN\n",
    "    \"\"\"\n",
    "    VERB_DEPS = ['ROOT', 'conj', 'relcl', 'advcl', 'ccomp']\n",
    "\n",
    "    AUXILIARY_MODALS = [\n",
    "        'can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, tok=None, clause=None, number_person='pl'):\n",
    "        \"\"\"\n",
    "        If the verb comes from a fragment without a subject, then default conjugation is past plural.\n",
    "        \"\"\"\n",
    "        self.is_parsed = False\n",
    "        self.break_recursion = False\n",
    "        self.tok = tok\n",
    "        self.clause = clause\n",
    "        self.aux = []\n",
    "        self.nsubj = None\n",
    "        self.do = False\n",
    "        self.been = False\n",
    "        self.number_person = number_person\n",
    "        self.is_past = False\n",
    "        self.is_future = False\n",
    "        self.have_pres = False\n",
    "        self.have_past = False\n",
    "        self.is_modal = False\n",
    "        self.is_participle = False\n",
    "        if self.tok and self.clause:\n",
    "            self.parse()\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f\"\"\"\n",
    "        is parsed: {self.is_parsed}\n",
    "        verb: {self.tok.lower_}\n",
    "        verb lemma: {self.tok.lemma_}\n",
    "        verb dependency label: {self.tok.lemma_}\n",
    "        verb constituent tag: {self.tok.tag_}\"\"\"\n",
    "        for i, a in enumerate(self.aux):\n",
    "            s += f\"\"\"\n",
    "        aux {i}: {a.lower_}\n",
    "        aux {i} lemma: {a.lemma_}\n",
    "        aux {i} dependency label: {a.dep_}\"\"\"\n",
    "        nsubj = self.nsubj.text if self.nsubj else None\n",
    "        s += f\"\"\"\n",
    "        subject: {self.nsubj}\n",
    "        number_person: {self.number_person}\n",
    "        has 'do': {self.do}\n",
    "        has 'been': {self.been}\n",
    "        is past tense: {self.is_past}\n",
    "        is future tense: {self.is_future}\n",
    "        is participle: {self.is_participle}\n",
    "        has 'have' in present tense: {self.have_pres}\n",
    "        has 'have' in past tense: {self.have_past}\n",
    "        has modal: {self.is_modal}\n",
    "\"\"\"\n",
    "        return s\n",
    "    \n",
    "    def parse(self):\n",
    "        if not self.tok or not self.clause:\n",
    "            raise Exception(\n",
    "                'Verb.parse_verb() requires the `tok` and `clause` '\n",
    "                'variables to be set.')\n",
    "        if self.break_recursion:\n",
    "            raise Exception(\n",
    "                'There is a circular dependency among conjunctive verbs.')\n",
    "        # Reset variables.\n",
    "        self.aux = []\n",
    "        self.do = False\n",
    "        self.been = False\n",
    "        self.have_pres = False\n",
    "        self.have_past = False\n",
    "        self.is_modal = False\n",
    "        self.is_past = False\n",
    "        self.is_future = False\n",
    "        # Check for previous verb joined by conjunction.\n",
    "        self.break_recursion = True\n",
    "        prev_verb = self.clause.prev_verb(self)\n",
    "        self.break_recursion = False\n",
    "        if prev_verb:\n",
    "            self.nsubj = prev_verb.nsubj\n",
    "            self.number_person = prev_verb.number_person\n",
    "            for child in self.tok.children:\n",
    "                if child.lemma_ == 'not':\n",
    "                    self.not_token = child\n",
    "                elif child.dep_ == 'aux' or child.dep_ == 'auxpass':\n",
    "                    self.aux.append(child)\n",
    "            if not self.aux:\n",
    "                if prev_verb.do:\n",
    "                    # Special exception: He did not walk but talked.\n",
    "                    if self.tok.tag_ == 'VBD':\n",
    "                        self.do = False\n",
    "                        self.aux = []\n",
    "                    else:\n",
    "                        self.do = True\n",
    "                        self.aux = prev_verb.aux\n",
    "                else:\n",
    "                    self.do = False\n",
    "                    self.aux = prev_verb.aux\n",
    "                self.been = prev_verb.been\n",
    "                self.have_pres = prev_verb.have_pres\n",
    "                self.have_past = prev_verb.have_past\n",
    "                self.is_modal = prev_verb.is_modal\n",
    "                self.is_past = prev_verb.is_past\n",
    "                self.is_future = prev_verb.is_future\n",
    "            else:\n",
    "                self.is_past = self._is_past()\n",
    "            # Calculate negation status.\n",
    "            # Algo: calculate negation status of previous verb\n",
    "            #       then calculate neg of current verb by\n",
    "            #       searching for not/n't/but\n",
    "            #\n",
    "            # * \"not\"/\"n't\" have dep_ == 'neg'\n",
    "            # * \"but\" has dep_ == 'cc' and is child of\n",
    "            #   the first verb of conjunction\n",
    "            #\n",
    "            # Ex:\n",
    "            #   did not talk or walk\n",
    "            #   did not talk but walked and balked\n",
    "            #   did talk but didn't walk or balk\n",
    "            #   didn't talk but did walk and balk\n",
    "        else:\n",
    "            # Iterates children in order of appearance.\n",
    "            for child in self.tok.children:\n",
    "                if child.dep_ == 'nsubj' or child.dep_ == 'nsubjpass':\n",
    "                    self.nsubj = child\n",
    "                elif child.dep_ == 'aux' or child.dep_ == 'auxpass':\n",
    "                    self.aux.append(child)\n",
    "            for a in self.aux:\n",
    "                if a.lemma_ == 'do':\n",
    "                    self.do = True\n",
    "                elif a.lower_ == 'been':\n",
    "                    self.been = True\n",
    "                elif a.lower_ == 'will':\n",
    "                    self.is_future = True\n",
    "                if (a.lower_ == 'have' or a.lower_ == 'has'):\n",
    "                    self.have_pres = True\n",
    "                if a.lower_ == 'had':\n",
    "                    self.have_past = True\n",
    "            self.is_modal = self.aux and self._is_aux_modal(self.aux[0])\n",
    "            self.number_person = self._number_person(self.nsubj)\n",
    "            self.is_past = self._is_past()\n",
    "        self.is_participle = self._is_participle(self.tok)\n",
    "        self.is_parsed = True\n",
    "\n",
    "    def transform_to_present_str(self, tok):\n",
    "        \"\"\"\n",
    "        Takes in a token. If the token is this verb or one of its auxiliaries,\n",
    "        then it converts it to present tense.\n",
    "        \n",
    "        Assumes that `self` is a past tense verb.\n",
    "        \n",
    "        Rules:\n",
    "        * past > present\n",
    "        * had + ppart > has/have + ppart\n",
    "        * had + been + ppart > has/have + been + ppart\n",
    "        * was + ppart > is + ppart\n",
    "        * did > does, had > has/have, was > is\n",
    "        * would have + ppart > would + inf\n",
    "        * would have + been + ppart> would be + ppart\n",
    "        \"\"\"\n",
    "        if self.aux and tok == self.aux[0]:\n",
    "            if tok.lemma_ == 'do':\n",
    "                return conjugate('do', self.number_person) + tok.whitespace_\n",
    "            elif self.is_modal:\n",
    "                return tok.text_with_ws\n",
    "            elif self.is_participle and tok.lower_ == 'has':\n",
    "                return conjugate('have', self.number_person) + tok.whitespace_\n",
    "            else:\n",
    "                return conjugate(tok.lemma_, self.number_person) + tok.whitespace_\n",
    "        elif tok in self.aux:\n",
    "            if self.is_modal and not self.is_future and tok.lower_ == 'have':\n",
    "                return ''\n",
    "            elif self.is_modal and not self.is_future and tok.lower_ == 'been':\n",
    "                return 'be' + tok.whitespace_\n",
    "            else:\n",
    "                return tok.text_with_ws\n",
    "        elif tok == self.tok:\n",
    "            if not self.aux:\n",
    "                return conjugate(tok.lemma_, self.number_person) + tok.whitespace_\n",
    "            elif self.is_modal and not self.been and not self.is_future:\n",
    "                return tok.lemma_ + tok.whitespace_\n",
    "            else:\n",
    "                return tok.text_with_ws\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    def _is_aux_modal(cls, tok):\n",
    "        return tok.lower_ in cls.AUXILIARY_MODALS\n",
    "\n",
    "    @classmethod\n",
    "    def _contains_one_of(cls, haystack, needles):\n",
    "        for item in haystack:\n",
    "            for needle in needles:\n",
    "                if item == needle:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def _number_person(cls, token):\n",
    "        \"\"\"\n",
    "        Expects a token with POS == 'NOUN'.\n",
    "        \"\"\"\n",
    "        # Default is plural.\n",
    "        if not token:\n",
    "            return 'pl'\n",
    "        for tok in token.children:\n",
    "            if tok.lower_ == 'and':\n",
    "                return 'pl'\n",
    "        if token.tag_ == 'NNPS' or token.tag_ == 'NNS' or token.lower_ == 'we' or token.lower_ == 'they':\n",
    "            return 'pl'\n",
    "        elif token.lower_ == 'i':\n",
    "            return '1sg'\n",
    "        elif token.lower_ == 'you':\n",
    "            return '2sg'\n",
    "        else:\n",
    "            return '3sg'\n",
    "\n",
    "    def _is_past(self):\n",
    "        if self.is_future:\n",
    "            return False\n",
    "        if self.do:\n",
    "            return self._is_past_tok(self.aux[0], self.number_person)\n",
    "        else:\n",
    "            if self.aux and self._is_past_tok(self.aux[0], self.number_person):\n",
    "                return True\n",
    "            elif self._is_past_tok(self.tok, self.number_person):\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    @classmethod\n",
    "    def _is_past_tok(cls, tok, number_person=None):\n",
    "        \"\"\"\n",
    "        Is `verb` past tense, where `verb` has lemma `lemma`\n",
    "        and number/person `number_person`?\n",
    "        \"\"\"\n",
    "        PAST_CONJ = {\n",
    "            '1sg': '1sgp',\n",
    "            '2sg': '2sgp',\n",
    "            '3sg': '3sgp',\n",
    "            'pl': 'ppl',\n",
    "            'part': 'ppart',\n",
    "        }\n",
    "        if tok.tag_ == 'VBN' or tok.tag_ == 'VBD':\n",
    "            return True\n",
    "        if number_person:\n",
    "            return conjugate(tok.lemma_, PAST_CONJ[number_person]) == tok.text\n",
    "        return (\n",
    "            conjugate(tok.lemma_, '1sgp') == tok.text\n",
    "            or conjugate(tok.lemma_, '2sgp') == tok.text\n",
    "            or conjugate(tok.lemma_, '3sgp') == tok.text\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _is_participle(cls, tok):\n",
    "        \"\"\"\n",
    "        Expects a token.\n",
    "        \"\"\"\n",
    "        return tok.tag_ == 'VBG' or tok.tag_ == 'VBN'\n",
    "\n",
    "\n",
    "class Clause(object):\n",
    "    def __init__(self, span):\n",
    "        self.verbs = []\n",
    "        self.span = span\n",
    "\n",
    "    def prev_verb(self, verb):\n",
    "        \"\"\"\n",
    "        If a verb is connected by a conjunction to a previous verb,\n",
    "        then get that verb.\n",
    "        \"\"\"\n",
    "        prev_verb = None\n",
    "        if verb.tok.dep_ == 'conj':\n",
    "            for tok in verb.tok.ancestors:\n",
    "                if tok.dep_ in VERB_DEPS:\n",
    "                    for v in self.verbs:\n",
    "                        if v.tok == tok:\n",
    "                            prev_verb = v\n",
    "                            if not prev_verb.is_parsed:\n",
    "                                prev_verb.parse()\n",
    "                    break\n",
    "        return prev_verb\n",
    "    \n",
    "    def parse_verbs(self):\n",
    "        self.verbs = []\n",
    "        first = True\n",
    "        # Depth-first search to find verbs.\n",
    "        s = []\n",
    "        s.append(self.span)\n",
    "        while s:\n",
    "            span = s.pop()\n",
    "            if 'S' in span._.labels or 'SBAR' in span._.labels:\n",
    "                if first:\n",
    "                    first = False\n",
    "                else:\n",
    "                    continue\n",
    "            elif len(span) == 1 and span[0].dep_ in Verb.VERB_DEPS:\n",
    "                self.verbs.append(Verb(span[0], self))\n",
    "            s.extend(reversed(list(span._.children)))\n",
    "        \n",
    "    def transform_present(self):\n",
    "        self.parse_verbs()\n",
    "        past_verbs = [v for v in self.verbs if v.is_past]\n",
    "        first = True\n",
    "        new_text = ''\n",
    "        #for v in verbs:\n",
    "        #    print(str(v))\n",
    "        # Depth-first search to transform past to present.\n",
    "        s = []\n",
    "        s.append(self.span)\n",
    "        while s:\n",
    "            span = s.pop()\n",
    "            if len(span) == 1:\n",
    "                span_is_past_verb = False\n",
    "                if span[0].pos_ == 'VERB':\n",
    "                    for v in past_verbs:\n",
    "                        present = v.transform_to_present_str(span[0])\n",
    "                        if present is not None:\n",
    "                            new_text += present\n",
    "                            span_is_past_verb = True\n",
    "                            break\n",
    "                if not span_is_past_verb:\n",
    "                    new_text += span.text_with_ws\n",
    "            elif 'S' in span._.labels or 'SBAR' in span._.labels:\n",
    "                if first:\n",
    "                    first = False\n",
    "                    s.extend(reversed(list(span._.children)))\n",
    "                else:\n",
    "                    ws = ' ' if span.text_with_ws[-1] == ' ' else ''\n",
    "                    new_text += Clause(span).transform_present() + ws\n",
    "            else:\n",
    "                s.extend(reversed(list(span._.children)))\n",
    "        new_text = new_text.replace(' .', '.').replace(' ,', ',')\n",
    "        if new_text and new_text[-1] == ' ':\n",
    "            new_text = new_text[:-1]\n",
    "        return new_text\n",
    "\n",
    "class Sentence(object):\n",
    "    def __init__(self, span):\n",
    "        self.span = span\n",
    "    \n",
    "    def transform_present(self):\n",
    "        if not self.span:\n",
    "            raise Exception(\n",
    "                'Sentence.transform_present() requires the sentence span to be set.')\n",
    "        try:\n",
    "            text = Clause(self.span).transform_present()\n",
    "            if text:\n",
    "                text = text[0].upper() + text[1:]\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print('There was an error parsing the following sentence')\n",
    "            print()\n",
    "            print(self.span.text)\n",
    "            print()\n",
    "            print('with parse:')\n",
    "            print()\n",
    "            print(self.span._.parse_string)\n",
    "            print()\n",
    "            print(str(e) + '\\n' + traceback.format_exc())\n",
    "            return self.span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "has have VERB VBZ aux []\n",
      "been be VERB VBN aux []\n",
      "throwing throw VERB VBG ROOT [boy, has, been, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the, bought]\n",
      "that that ADJ WDT dobj []\n",
      "he -PRON- PRON PRP nsubj []\n",
      "bought buy VERB VBD relcl [that, he, at]\n",
      "at at ADP IN prep [store]\n",
      "the the DET DT det []\n",
      "store store NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBZ has) (VP (VBN been) (VP (VBG throwing) (NP (NP (DT the) (NN ball)) (SBAR (WHNP (WDT that)) (S (NP (PRP he)) (VP (VBD bought) (PP (IN at) (NP (DT the) (NN store)))))))))) (. .))\n",
      "[The boy, has been throwing the ball that he bought at the store, .]\n"
     ]
    }
   ],
   "source": [
    "parse(\"The boy has been throwing the ball that he bought at the store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform_present_preserve_present():\n",
    "    assert transform_present(\"The boy has been throwing and catching.\", True) == \"The boy has been throwing and catching.\"\n",
    "    assert transform_present(\"The boy would throw and catch the ball.\", True) == \"The boy would throw and catch the ball.\"\n",
    "    assert transform_present(\"The boy would have a ball for Christmas.\", True) == \"The boy would have a ball for Christmas.\"\n",
    "    assert transform_present('The boy has thrown and caught the ball.', True) == 'The boy has thrown and caught the ball.'\n",
    "    assert transform_present(\"The boy hasn't thrown or caught the ball.\", True) == \"The boy hasn't thrown or caught the ball.\"\n",
    "    assert transform_present(\"The boy is throwing and catching the ball and catching it.\", True) == \"The boy is throwing and catching the ball and catching it.\"\n",
    "    assert transform_present(\"The ball is being thrown and caught by the boy.\", True) == \"The ball is being thrown and caught by the boy.\"\n",
    "    assert transform_present(\"The ball is thrown and caught by the boy.\", True) == \"The ball is thrown and caught by the boy.\"\n",
    "    \n",
    "def test_transform_present_preserve_future():\n",
    "    assert transform_present(\"The boy will throw the ball and hit it.\", True) == \"The boy will throw the ball and hit it.\"\n",
    "    assert transform_present(\"The boy will have thrown the ball before catching it.\", True) == \"The boy will have thrown the ball before catching it.\"\n",
    "    assert transform_present(\"The ball will have been thrown and caught by the boy.\", True) == \"The ball will have been thrown and caught by the boy.\"\n",
    "    assert transform_present(\"The boy will be throwing and catching the ball.\", True) == \"The boy will be throwing and catching the ball.\"\n",
    "    assert transform_present(\"The ball will be thrown and caught by the boy.\", True) == \"The ball will be thrown and caught by the boy.\"\n",
    "\n",
    "def test_transform_present_conjunctions():\n",
    "    assert transform_present(\"The boy threw the ball and hid.\", True) == \"The boy throws the ball and hides.\"\n",
    "    assert transform_present(\"The boy is going and was going.\", True) == \"The boy is going and is going.\"\n",
    "    assert transform_present(\"The boy did not walk but talked.\", True) == \"The boy does not walk but talks.\"\n",
    "    assert transform_present(\"The boy walked but a mile talking with a friend.\", True) == \"The boy walks but a mile talking with a friend.\"\n",
    "    assert transform_present(\"The boy walked not even a mile before stopping.\", True) == \"The boy walks not even a mile before stopping.\"\n",
    "\n",
    "def test_transform_present_complex():\n",
    "    assert transform_present(\"The boy has been throwing the ball that he bought at the store.\", True) == \"The boy has been throwing the ball that he buys at the store.\"\n",
    "    assert transform_present(\"The boy had been throwing the ball when it hit a window.\", True) == \"The boy has been throwing the ball when it hits a window.\"\n",
    "    assert transform_present(\"The boy has thrown the ball that hit a window.\", True) == \"The boy has thrown the ball that hits a window.\"\n",
    "    assert transform_present(\"The boy threw the ball which hit a window.\", True) == \"The boy throws the ball which hits a window.\"\n",
    "    assert transform_present(\"The boy threw the ball while the dog fetched it.\", True) == \"The boy throws the ball while the dog fetches it.\"\n",
    "    assert transform_present(\"The boy had thrown the ball, and it flew high.\", True) == \"The boy has thrown the ball, and it flies high.\"\n",
    "    assert transform_present(\"The boy dropped the ball while throwing it.\", True) == \"The boy drops the ball while throwing it.\"\n",
    "    assert transform_present(\"The boy was throwing the ball, but it kept falling to the ground.\", True) == \"The boy is throwing the ball, but it keeps falling to the ground.\"\n",
    "    assert transform_present(\"Did the boy throw the ball that broke the window?\", True) == \"Does the boy throw the ball that breaks the window?\"\n",
    "    #assert transform_present(\"The fallen ball was thrown by the boy.\")\n",
    "    \n",
    "def test_transform_present_past_tenses():\n",
    "    assert transform_present('The boy threw the ball.', True) == 'The boy throws the ball.'\n",
    "    assert transform_present('The boy did throw the ball.', True) == 'The boy does throw the ball.'\n",
    "\n",
    "    assert transform_present(\"The boy didn't throw the ball.\", True) == \"The boy doesn't throw the ball.\"\n",
    "    assert transform_present(\"The boy did not throw the ball.\", True) == \"The boy does not throw the ball.\"\n",
    "\n",
    "\n",
    "    assert transform_present('The boy had thrown the ball.', True) == 'The boy has thrown the ball.'\n",
    "    assert transform_present('The boy was throwing the ball.', True) == 'The boy is throwing the ball.'\n",
    "    assert transform_present('The boy had been throwing the ball.', True) == 'The boy has been throwing the ball.'\n",
    "\n",
    "    assert transform_present(\"The boy hadn't thrown the ball.\", True) == \"The boy hasn't thrown the ball.\"\n",
    "    assert transform_present(\"The boy wasn't throwing the ball.\", True) == \"The boy isn't throwing the ball.\"\n",
    "    assert transform_present(\"The boy hadn't been throwing the ball.\", True) == \"The boy hasn't been throwing the ball.\"\n",
    "\n",
    "    assert transform_present('The boy would have thrown the ball.', True) == 'The boy would throw the ball.'\n",
    "    assert transform_present('The boy could have thrown the ball.', True) == 'The boy could throw the ball.'\n",
    "    assert transform_present('The boy must have thrown the ball.', True) == 'The boy must throw the ball.'\n",
    "    assert transform_present(\"The boy wouldn't have thrown the ball.\", True) == \"The boy wouldn't throw the ball.\"\n",
    "\n",
    "    assert transform_present('The ball was thrown by the boy.', True) == 'The ball is thrown by the boy.'\n",
    "    assert transform_present('The ball was being thrown by the boy.', True) == 'The ball is being thrown by the boy.'\n",
    "    assert transform_present(\"The ball wasn't being thrown by the boy.\", True) == \"The ball isn't being thrown by the boy.\"\n",
    "    assert transform_present('The ball would have been thrown by the boy.', True) == 'The ball would be thrown by the boy.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boy has been throwing and catching.\n",
      "The boy would throw and catch the ball.\n",
      "The boy would have a ball for Christmas.\n",
      "The boy has thrown and caught the ball.\n",
      "The boy hasn't thrown or caught the ball.\n",
      "The boy is throwing and catching the ball and catching it.\n",
      "The ball is being thrown and caught by the boy.\n",
      "The ball is thrown and caught by the boy.\n",
      "The boy will throw the ball and hit it.\n",
      "The boy will have thrown the ball before catching it.\n",
      "The ball will have been thrown and caught by the boy.\n",
      "The boy will be throwing and catching the ball.\n",
      "The ball will be thrown and caught by the boy.\n"
     ]
    }
   ],
   "source": [
    "test_transform_present_preserve_present()\n",
    "test_transform_present_preserve_future()\n",
    "#test_transform_present_conjunctions()\n",
    "#test_transform_present_complex()\n",
    "#test_transform_present_past_tenses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -PRON- PRON PRP nsubj []\n",
      "had have VERB VBD aux []\n",
      "arranged arrange VERB VBN ROOT [He, had, steer, .]\n",
      "that that ADP IN mark []\n",
      "the the DET DT det []\n",
      "skipper skipper NOUN NN nsubj [the]\n",
      "should should VERB MD aux []\n",
      "steer steer VERB VB ccomp [that, skipper, should, breakfasted]\n",
      "while while ADP IN mark []\n",
      "he -PRON- PRON PRP nsubj [and, Harris]\n",
      "and and CCONJ CC cc []\n",
      "Miss miss PROPN NNP compound []\n",
      "Harris harris PROPN NNP conj [Miss]\n",
      "breakfasted breakfast VERB VBD advcl [while, he]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (PRP He)) (VP (VBD had) (VP (VBN arranged) (SBAR (SBAR (IN that) (S (NP (DT the) (NN skipper)) (VP (MD should) (VB steer)))) (SBAR (IN while) (S (NP (NP (PRP he)) (CC and) (NP (NNP Miss) (NNP Harris))) (VP (VBD breakfasted))))))) (. .))\n",
      "[He, had arranged that the skipper should steer while he and Miss Harris breakfasted, .]\n",
      "\n",
      "        verb: arranged\n",
      "        verb lemma: arrange\n",
      "        verb dependency label: arrange\n",
      "        verb constituent tags: \n",
      "        aux 0: had\n",
      "        aux 0 lemma: have\n",
      "        aux 0 dependency label: aux\n",
      "        negation: False\n",
      "        subject: He\n",
      "        conjugation: 3sg\n",
      "        has 'do': False\n",
      "        is past tense: True\n",
      "        has 'have' in present tense: False\n",
      "        has 'have' in past tense: True\n",
      "        has modal: False\n",
      "\n",
      "1\n",
      "3\n",
      "\n",
      "        verb: steer\n",
      "        verb lemma: steer\n",
      "        verb dependency label: steer\n",
      "        verb constituent tags: \n",
      "        aux 0: should\n",
      "        aux 0 lemma: should\n",
      "        aux 0 dependency label: aux\n",
      "        negation: False\n",
      "        subject: skipper\n",
      "        conjugation: 3sg\n",
      "        has 'do': False\n",
      "        is past tense: False\n",
      "        has 'have' in present tense: False\n",
      "        has 'have' in past tense: False\n",
      "        has modal: True\n",
      "\n",
      "the_skipper_should_steer\n",
      "that_the_skipper_should_steer\n",
      "\n",
      "        verb: breakfasted\n",
      "        verb lemma: breakfast\n",
      "        verb dependency label: breakfast\n",
      "        verb constituent tags: VP\n",
      "        negation: False\n",
      "        subject: he\n",
      "        conjugation: pl\n",
      "        has 'do': False\n",
      "        is past tense: True\n",
      "        has 'have' in present tense: []\n",
      "        has 'have' in past tense: []\n",
      "        has modal: []\n",
      "\n",
      "\n",
      "        verb: harris\n",
      "        verb lemma: harris\n",
      "        verb dependency label: harris\n",
      "        verb constituent tags: \n",
      "        negation: False\n",
      "        subject: He\n",
      "        conjugation: 3sg\n",
      "        has 'do': False\n",
      "        is past tense: False\n",
      "        has 'have' in present tense: []\n",
      "        has 'have' in past tense: []\n",
      "        has modal: []\n",
      "\n",
      "3\n",
      "he_and_Miss_Harris_breakfast\n",
      "while_he_and_Miss_Harris_breakfast\n",
      "that_the_skipper_should_steer_while_he_and_Miss_Harris_breakfast\n",
      "He_has_arranged_that_the_skipper_should_steer_while_he_and_Miss_Harris_breakfast.\n",
      "He has arranged that the skipper should steer while he and Miss Harris breakfast.\n"
     ]
    }
   ],
   "source": [
    "s = \"He had arranged that the skipper should steer while he and Miss Harris breakfasted.\"\n",
    "parse(s)\n",
    "doc = nlp(s)\n",
    "sent = next(doc.sents)\n",
    "print(transform_present_span(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "threw throw VERB VBD ROOT [boy, ball, and, hid, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      "and and CCONJ CC cc []\n",
      "hid hide VERB VBD conj []\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VP (VBD threw) (NP (DT the) (NN ball))) (CC and) (VP (VBD hid))) (. .))\n",
      "[The boy, threw the ball and hid, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "is be VERB VBZ aux []\n",
      "going go VERB VBG ROOT [boy, is, and, going, .]\n",
      "and and CCONJ CC cc []\n",
      "was be VERB VBD aux []\n",
      "going go VERB VBG conj [was]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VP (VBZ is) (VP (VBG going))) (CC and) (VP (VBD was) (VP (VBG going)))) (. .))\n",
      "[The boy, is going and was going, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "did do VERB VBD aux []\n",
      "not not ADV RB neg []\n",
      "walk walk VERB VB ROOT [boy, did, not, but, talked, .]\n",
      "but but CCONJ CC cc []\n",
      "talked talk VERB VBD conj []\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VP (VBD did) (RB not) (VP (VB walk))) (CC but) (VP (VBD talked))) (. .))\n",
      "[The boy, did not walk but talked, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "walked walk VERB VBD ROOT [boy, but, talking, .]\n",
      "but but CCONJ CC cc []\n",
      "a a DET DT det []\n",
      "mile mile NOUN NN npadvmod [a]\n",
      "talking talk VERB VBG conj [mile, with]\n",
      "with with ADP IN prep [friend]\n",
      "a a DET DT det []\n",
      "friend friend NOUN NN pobj [a]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VP (VBD walked)) (CC but) (NP (DT a) (NN mile)) (S (VP (VBG talking) (PP (IN with) (NP (DT a) (NN friend)))))) (. .))\n",
      "[The boy, walked but a mile talking with a friend, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "walked walk VERB VBD ROOT [boy, not, before, .]\n",
      "not not ADV RB neg []\n",
      "even even ADV RB advmod []\n",
      "a a DET DT det []\n",
      "mile mile NOUN NN npadvmod [even, a]\n",
      "before before ADP IN prep [mile, stopping]\n",
      "stopping stop VERB VBG pcomp []\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD walked) (NP (RB not) (RB even) (DT a) (NN mile)) (PP (IN before) (S (VP (VBG stopping))))) (. .))\n",
      "[The boy, walked not even a mile before stopping, .]\n"
     ]
    }
   ],
   "source": [
    "parse(\"The boy threw the ball and hid.\")\n",
    "print('*********')\n",
    "parse(\"The boy is going and was going.\")\n",
    "print('*********')\n",
    "parse(\"The boy did not walk but talked.\")\n",
    "print('*********')\n",
    "parse(\"The boy walked but a mile talking with a friend.\")\n",
    "print('*********')\n",
    "parse(\"The boy walked not even a mile before stopping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "had have VERB VBD aux []\n",
      "been be VERB VBN aux []\n",
      "throwing throw VERB VBG ROOT [boy, had, been, ball, hit, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      "when when ADV WRB advmod []\n",
      "it -PRON- PRON PRP nsubj []\n",
      "hit hit VERB VBD advcl [when, it, window]\n",
      "a a DET DT det []\n",
      "window window NOUN NN dobj [a]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD had) (VP (VBN been) (VP (VBG throwing) (NP (DT the) (NN ball)) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBD hit) (NP (DT a) (NN window)))))))) (. .))\n",
      "[The boy, had been throwing the ball when it hit a window, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "has have VERB VBZ aux []\n",
      "thrown throw VERB VBN ROOT [boy, has, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the, hit]\n",
      "that that ADJ WDT nsubj []\n",
      "hit hit VERB VBD relcl [that, window]\n",
      "a a DET DT det []\n",
      "window window NOUN NN dobj [a]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBZ has) (VP (VBN thrown) (NP (NP (DT the) (NN ball)) (SBAR (WHNP (WDT that)) (S (VP (VBD hit) (NP (DT a) (NN window)))))))) (. .))\n",
      "[The boy, has thrown the ball that hit a window, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "threw throw VERB VBD ROOT [boy, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the, hit]\n",
      "which which ADJ WDT nsubj []\n",
      "hit hit VERB VBD relcl [which, window]\n",
      "a a DET DT det []\n",
      "window window NOUN NN dobj [a]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD threw) (NP (NP (DT the) (NN ball)) (SBAR (WHNP (WDT which)) (S (VP (VBD hit) (NP (DT a) (NN window))))))) (. .))\n",
      "[The boy, threw the ball which hit a window, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "threw throw VERB VBD ROOT [boy, ball, fetched, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      "while while ADP IN mark []\n",
      "the the DET DT det []\n",
      "dog dog NOUN NN nsubj [the]\n",
      "fetched fetch VERB VBD advcl [while, dog, it]\n",
      "it -PRON- PRON PRP dobj []\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD threw) (NP (DT the) (NN ball)) (SBAR (IN while) (S (NP (DT the) (NN dog)) (VP (VBD fetched) (NP (PRP it)))))) (. .))\n",
      "[The boy, threw the ball while the dog fetched it, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "had have VERB VBD aux []\n",
      "thrown throw VERB VBN ROOT [boy, had, ball, ,, and, flew]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      ", , PUNCT , punct []\n",
      "and and CCONJ CC cc []\n",
      "it -PRON- PRON PRP nsubj []\n",
      "flew fly VERB VBD conj [it, high, .]\n",
      "high high ADJ JJ advmod []\n",
      ". . PUNCT . punct []\n",
      "(S (S (NP (DT The) (NN boy)) (VP (VBD had) (VP (VBN thrown) (NP (DT the) (NN ball))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBD flew) (ADVP (JJ high)))) (. .))\n",
      "[The boy had thrown the ball, ,, and, it flew high, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "dropped drop VERB VBD ROOT [boy, ball, throwing, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      "while while ADP IN mark []\n",
      "throwing throw VERB VBG advcl [while, it]\n",
      "it -PRON- PRON PRP dobj []\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD dropped) (NP (DT the) (NN ball)) (SBAR (IN while) (S (VP (VBG throwing) (NP (PRP it)))))) (. .))\n",
      "[The boy, dropped the ball while throwing it, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "was be VERB VBD aux []\n",
      "throwing throw VERB VBG ROOT [boy, was, ball, ,, but, kept]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      ", , PUNCT , punct []\n",
      "but but CCONJ CC cc []\n",
      "it -PRON- PRON PRP nsubj []\n",
      "kept keep VERB VBD conj [it, falling, .]\n",
      "falling fall VERB VBG xcomp [to]\n",
      "to to ADP IN prep [ground]\n",
      "the the DET DT det []\n",
      "ground ground NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (S (NP (DT The) (NN boy)) (VP (VBD was) (VP (VBG throwing) (NP (DT the) (NN ball))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VBD kept) (S (VP (VBG falling) (PP (IN to) (NP (DT the) (NN ground))))))) (. .))\n",
      "[The boy was throwing the ball, ,, but, it kept falling to the ground, .]\n",
      "*********\n",
      "Did do VERB VBD aux []\n",
      "the the DET DT det []\n",
      "boy boy NOUN NN nsubj [the]\n",
      "throw throw VERB VB ROOT [Did, boy, ball, ?]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the, broke]\n",
      "that that ADJ WDT nsubj []\n",
      "broke break VERB VBD relcl [that, window]\n",
      "the the DET DT det []\n",
      "window window NOUN NN dobj [the]\n",
      "? ? PUNCT . punct []\n",
      "(SQ (VBD Did) (NP (DT the) (NN boy)) (VP (VB throw) (NP (NP (DT the) (NN ball)) (SBAR (WHNP (WDT that)) (S (VP (VBD broke) (NP (DT the) (NN window))))))) (. ?))\n",
      "[Did, the boy, throw the ball that broke the window, ?]\n",
      "*********\n",
      "The the DET DT det []\n",
      "fallen fall VERB VBN amod []\n",
      "ball ball NOUN NN nsubjpass [The, fallen]\n",
      "was be VERB VBD auxpass []\n",
      "thrown throw VERB VBN ROOT [ball, was, by, .]\n",
      "by by ADP IN agent [boy]\n",
      "the the DET DT det []\n",
      "boy boy NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (VBN fallen) (NN ball)) (VP (VBD was) (VP (VBN thrown) (PP (IN by) (NP (DT the) (NN boy))))) (. .))\n",
      "[The fallen ball, was thrown by the boy, .]\n"
     ]
    }
   ],
   "source": [
    "# SBAR WHADVP, SBAR WHNP, SBAR S, S S, S S\n",
    "parse(\"The boy had been throwing the ball when it hit a window.\")\n",
    "print('*********')\n",
    "parse(\"The boy has thrown the ball that hit a window.\")\n",
    "print('*********')\n",
    "parse(\"The boy threw the ball which hit a window.\")\n",
    "print('*********')\n",
    "parse(\"The boy threw the ball while the dog fetched it.\")\n",
    "print('*********')\n",
    "parse(\"The boy had thrown the ball, and it flew high.\")\n",
    "print('*********')\n",
    "parse(\"The boy dropped the ball while throwing it.\")\n",
    "print('*********')\n",
    "parse(\"The boy was throwing the ball, but it kept falling to the ground.\")\n",
    "print('*********')\n",
    "parse(\"Did the boy throw the ball that broke the window?\")\n",
    "print('*********')\n",
    "parse(\"The fallen ball was thrown by the boy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "did do VERB VBD aux []\n",
      "not not ADV RB neg []\n",
      "throw throw VERB VB ROOT [boy, did, not, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD did) (RB not) (VP (VB throw) (NP (DT the) (NN ball)))) (. .))\n",
      "[The boy, did not throw the ball, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "had have VERB VBD aux []\n",
      "been be VERB VBN aux []\n",
      "throwing throw VERB VBG ROOT [boy, had, been, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD had) (VP (VBN been) (VP (VBG throwing) (NP (DT the) (NN ball))))) (. .))\n",
      "[The boy, had been throwing the ball, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "was be VERB VBD aux []\n",
      "n't not ADV RB neg []\n",
      "throwing throw VERB VBG ROOT [boy, was, n't, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (VBD was) (RB n't) (VP (VBG throwing) (NP (DT the) (NN ball)))) (. .))\n",
      "[The boy, wasn't throwing the ball, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "boy boy NOUN NN nsubj [The]\n",
      "should should VERB MD aux []\n",
      "have have VERB VB aux []\n",
      "thrown throw VERB VBN ROOT [boy, should, have, ball, .]\n",
      "the the DET DT det []\n",
      "ball ball NOUN NN dobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN boy)) (VP (MD should) (VP (VB have) (VP (VBN thrown) (NP (DT the) (NN ball))))) (. .))\n",
      "[The boy, should have thrown the ball, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "ball ball NOUN NN nsubjpass [The]\n",
      "was be VERB VBD aux []\n",
      "being be VERB VBG auxpass []\n",
      "thrown throw VERB VBN ROOT [ball, was, being, by, .]\n",
      "by by ADP IN agent [boy]\n",
      "the the DET DT det []\n",
      "boy boy NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN ball)) (VP (VBD was) (VP (VBG being) (VP (VBN thrown) (PP (IN by) (NP (DT the) (NN boy)))))) (. .))\n",
      "[The ball, was being thrown by the boy, .]\n",
      "*********\n",
      "The the DET DT det []\n",
      "ball ball NOUN NN nsubjpass [The]\n",
      "would would VERB MD aux []\n",
      "have have VERB VB aux []\n",
      "been be VERB VBN auxpass []\n",
      "thrown throw VERB VBN ROOT [ball, would, have, been, by, .]\n",
      "by by ADP IN agent [boy]\n",
      "the the DET DT det []\n",
      "boy boy NOUN NN pobj [the]\n",
      ". . PUNCT . punct []\n",
      "(S (NP (DT The) (NN ball)) (VP (MD would) (VP (VB have) (VP (VBN been) (VP (VBN thrown) (PP (IN by) (NP (DT the) (NN boy))))))) (. .))\n",
      "[The ball, would have been thrown by the boy, .]\n"
     ]
    }
   ],
   "source": [
    "parse(\"The boy did not throw the ball.\")\n",
    "print('*********')\n",
    "parse('The boy had been throwing the ball.')\n",
    "print('*********')\n",
    "parse(\"The boy wasn't throwing the ball.\")\n",
    "print('*********')\n",
    "parse('The boy should have thrown the ball.')\n",
    "print('*********')\n",
    "parse('The ball was being thrown by the boy.')\n",
    "print('*********')\n",
    "parse('The ball would have been thrown by the boy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no aux: vbz, vbp, vbd --> 'be' with the same conjugation as verb + ppart\n",
    "# The boy threw the ball --> The ball was thrown.\n",
    "# The boy throws the ball --> The ball is thrown.\n",
    "\n",
    "# 'will' aux: vbz, vbp --> 'be' + ppart\n",
    "# The boy will throw the ball --> The ball will be thrown.\n",
    "\n",
    "# 'do' conj aux --> 'be' with same conjugation as 'do'\n",
    "# The boy did throw the ball --> The ball was thrown.\n",
    "# The boy does throw the ball --> The ball is thrown.\n",
    "# The boy didn't throw the ball --> The ball wasn't thrown.\n",
    "# The boy doesn't throw the ball --> The ball isn't thrown.\n",
    "\n",
    "# 'be' conj aux: gerund --> 'being' + ppart\n",
    "# The boy was throwing the ball --> The ball was being thrown.\n",
    "# The boy is throwing the ball --> The ball is being thrown.\n",
    "# The boy will be throwing the ball --> The ball will be being thrown.\n",
    "\n",
    "# 'have' conj aux: ppart --> 'been' + ppart\n",
    "# The boy had thrown the ball --> The ball had been thrown.\n",
    "# The boy has thrown the ball --> The ball has been thrown.\n",
    "\n",
    "# 'will' + 'have' aux: ppart --> 'been' + ppart\n",
    "# The boy will have thrown the ball --> The ball will have been thrown.\n",
    "\n",
    "# 'have' conj + 'been' aux: vbg --> 'being' + ppart\n",
    "# The boy had been throwing the ball --> The ball had been being thrown.\n",
    "# The boy has been throwing the ball --> The ball has been being thrown.\n",
    "\n",
    "# 'will' + 'have' + 'been' aux: vbg --> 'being' + ppart\n",
    "# The boy will have been throwing the ball --> The ball will have been being thrown.\n",
    "\n",
    "# if verb has a direct object\n",
    "\n",
    "# except for 'do' aux:\n",
    "# 1. conjugate 'be' in the tense of the verb with the person and number of dobj\n",
    "\n",
    "# for 'do' aux:\n",
    "# 1. conjugate 'be' in the tense of 'do' with the person and number of dobj\n",
    "\n",
    "# for all\n",
    "# 3. change verb to conjugated 'be' + past participle\n",
    "# 4. replace subject with direct object\n",
    "\n",
    "# traverse breadth first\n",
    "# save subject noun phrase\n",
    "# save list of aux\n",
    "# save main verb\n",
    "# if find direct object, then perform transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def transform_passive(sent_text):\n",
    "    doc = nlp(sent_text)\n",
    "    trans_text = []\n",
    "    for sent in doc.sents:\n",
    "        trans_text.append(transform_passive_span(sent))\n",
    "    return ' '.join(trans_text)\n",
    "\n",
    "def transform_passive_span(sent):\n",
    "    try:\n",
    "        first = True\n",
    "        subject = None\n",
    "        aux = []\n",
    "        verb = None\n",
    "        dobj = None\n",
    "        q = deque()\n",
    "        q.append(sent)\n",
    "        while q:\n",
    "            span = q.popleft()\n",
    "            if 'S' in span._.labels:\n",
    "                if first:\n",
    "                    first = False\n",
    "                else:\n",
    "                    continue\n",
    "            elif not subject and 'NP' in span._.labels:\n",
    "                subject = span\n",
    "            elif len(span) == 1 and span[0].dep_ == 'aux':\n",
    "                aux.append(span)\n",
    "            elif len(span) == 1 and span[0].pos_ == 'VERB':\n",
    "                verb = span\n",
    "            elif len(span) == 1 and span[0].dep_ == 'dobj':\n",
    "                dobj = span\n",
    "                objekt = span\n",
    "                while objekt._.parent and 'VP' not in objekt._.labels:\n",
    "                    if 'NP' in objekt._.labels:\n",
    "                        break\n",
    "                    objekt = objekt._.parent            \n",
    "                break\n",
    "            elif contains_one_of(span._.labels, ('ADVP', 'PP', 'ADJP', 'PRN', 'QP', 'RRC', 'X')):\n",
    "                continue\n",
    "            q.extend(span._.children)\n",
    "        if not subject or not dobj: return sent.text\n",
    "        emphatic = aux and aux[0][0].lemma_ == 'do'\n",
    "        nsubj = find_nsubj(subject)\n",
    "        subj_conj = number_person(nsubj[0])\n",
    "        past_tense = (\n",
    "            is_past(aux[0][0], subj_conj) if emphatic\n",
    "            else is_past(verb[0], subj_conj)\n",
    "        )\n",
    "        participle = False if emphatic else is_participle(verb)\n",
    "        if participle:\n",
    "            conj = 'ppart' if past_tense else 'part'\n",
    "        else:\n",
    "            conj = number_person(dobj[0])\n",
    "            if past_tense:\n",
    "                conj = conj_to_past(conj)\n",
    "        if DEBUG:\n",
    "            print([a.text for a in aux])\n",
    "            print(nsubj.text, '|', dobj.text, '|', subject.text, '|', objekt.text, '|', verb.text)\n",
    "            print(conj)\n",
    "            print(past_tense)\n",
    "            print(participle)\n",
    "        new_text = ''\n",
    "        s = []\n",
    "        s.append(sent)\n",
    "        while s:\n",
    "            span = s.pop()\n",
    "            if span == subject:\n",
    "                new_text += object_to_subject(objekt) + subject[-1].whitespace_\n",
    "                continue\n",
    "            elif emphatic and span == aux[0]:\n",
    "                pass\n",
    "            elif span == verb:\n",
    "                new_text += conjugate('be', conj) + ' '\n",
    "                print(verb.text)\n",
    "                print(len(verb[0].whitespace_))\n",
    "                new_text += conjugate(verb[0].lemma_, 'ppart') + verb[0].whitespace_\n",
    "            elif span == objekt:\n",
    "                continue\n",
    "            elif len(span) == 1:\n",
    "                new_text += span.text_with_ws\n",
    "            s.extend(reversed(list(span._.children)))\n",
    "        return new_text.replace(' .', '.').replace(' ,', ',')\n",
    "    except Exception as e:\n",
    "        print('There was an error parsing the following sentence')\n",
    "        print()\n",
    "        print(sent.text)\n",
    "        print()\n",
    "        print('with parse:')\n",
    "        print()\n",
    "        print(sent._.parse_string)\n",
    "        print()\n",
    "        print(str(e) + '\\n' + traceback.format_exc())\n",
    "        return sent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n",
      "0\n",
      "the\n",
      "1\n",
      "greeted\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Soon after, the \"tall\" woman was greeted.'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Soon after, the man greeted the \"tall\" woman.')\n",
    "sent = next(doc.sents)\n",
    "print(sent[1].text)\n",
    "print(len(sent[1].whitespace_))\n",
    "print(sent[6].text)\n",
    "print(len(sent[6].whitespace_))\n",
    "transform_passive('Soon after, the man greeted the \"tall\" woman.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_token(sent, tok):\n",
    "    s = [sent]\n",
    "    while s:\n",
    "        span = s.pop()\n",
    "        if len(span) == 1 and span[0] == tok:\n",
    "            return span\n",
    "        s.extend(reversed(list(span._.children)))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text):\n",
    "    doc = nlp(text)\n",
    "    trans_text = []\n",
    "    for sent in doc.sents:\n",
    "        trans_text.append(transform_passive(transform_past_span(sent)))\n",
    "    return '\\n'.join(trans_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text/text-for-transform.txt', 'r') as fi:\n",
    "    with open('text/text-transformed.txt', 'w') as fo:\n",
    "        for i, line in enumerate(fi):\n",
    "            print(i, end='..', flush=True)\n",
    "            fo.write(transform(line), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1..2..3..4..5..There was an error parsing the following sentence\n",
      "\n",
      "Once their timelines converged \" naturally \" at the library  their first meeting in his chronology \n",
      "\n",
      "with parse:\n",
      "\n",
      "(FRAG (SBAR (IN Once) (NP (PRP$ their) (NNS timelines)) (VP (VBD converged) (ADVP (`` \")) (ADVP (RB naturally)) ('' \") (PP (IN at) (NP (DT the) (NN library))))) ( ) (NP (NP (PRP$ their) (JJ first) (NN meeting)) (PP (IN in) (NP (PRP$ his) (NN chronology)))) ( ))\n",
      "\n",
      "'NoneType' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-126-ca10ab007446>\", line 181, in transform_passive_span\n",
      "    subj_conj = number_person(nsubj[0])\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "6..7..8..9..10..11..12..13..14..15..16..17..18..19..20..21..22..23.."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-061e07f8f39d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-d9a95b6842f0>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrans_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrans_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_passive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_past_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__call__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/benepar/spacy_plugin.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mconstituent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPartialConstituentData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparse_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batched_parsed_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;31m# The optimized cython decoder implementation doesn't actually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# generate trees, only scores and span indices. Indices follow a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/benepar/base_parser.py\u001b[0m in \u001b[0;36m_batched_parsed_raw\u001b[0;34m(self, sentence_data_pairs)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchart_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_charts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchart_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/benepar/base_parser.py\u001b[0m in \u001b[0;36m_make_charts\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_charts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0minp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mout_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mchart_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('text/plot-summaries.txt', 'r') as fi:\n",
    "    with open('text/plot-summaries-transformed.txt', 'w') as fo:\n",
    "        i = 0\n",
    "        for line in fi:\n",
    "            i += 1\n",
    "            print(i, end='..', flush=True)\n",
    "            fo.write(transform(line), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL\n",
    "# [x] punctuation has spaces before it\n",
    "\n",
    "# PAST TENSE\n",
    "# [_] has known --> known\n",
    "#     She has known him most of her life.\n",
    "# [_] in a conjunction of verbs only the first is put into past tense\n",
    "#     He shoots and wounds the dog.\n",
    "# [_] \"may\" does not become \"might\"\n",
    "#     He may be greeting her.\n",
    "# [_] past tense transform preserves future; should change \"will\" to \"would\"\n",
    "#     She will remember to help him when he arrives.\n",
    "# [_] past tense of \"leave\" is conjugated as \"leaved\"\n",
    "# [_] verb should not be past tense in statement\n",
    "#     He requests she retreive the will.\n",
    "\n",
    "# PASSIVE\n",
    "# [_] broadest NP not used\n",
    "#     He amassed a number of survival skills.\n",
    "# [_] modals not turned to passive correctly\n",
    "#     He may greet her. --> She may be greeted. (NOT She may is greeted.)\n",
    "# [_] adverb should split auxilliary and primary verbs\n",
    "#     He quickly took the bag. --> The bag was quickly taken.\n",
    "# [_] conjunction of an intransitive and action verb uses object of action verb as subject of both\n",
    "#     He wishes to help her and gives her a hand.\n",
    "# [_] \"number of things\" is plural\n",
    "#     He knew a number of things. --> A number of things were known. (NOT was known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She known him most of her life .'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse('')\n",
    "#transform_passive('When he leaves, where he goes, or how long his trips will last are all beyond his control.')\n",
    "transform_past('She has known him most of her life.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/julianbrooke/GutenTag/blob/master/GutenTag.py\n",
    "# this class cleans away Project Gutenberg headers and footers, including copyright and transcriber notes\n",
    "class TextCleaner:\n",
    "    junk_indicators = (\"project gutenberg\",\" etext\",\" e-text\",\n",
    "                            \"http:\",\"distributed proofreading\",\n",
    "                            \"distributed\\nproofreading\", \" online\"\n",
    "                            \"html\",\"utf-8\",\"ascii\",\"transcriber's note\",\n",
    "                            \"scanner's note\", \"\\\\.net\",\"\\\\.org\",\"\\\\.com\",\n",
    "                            \"\\\\.edu\",\"www\\\\.\", \"electronic version\",\n",
    "                            \" email\",\"\\\\.uk\",\"digitized\", \"\\n\\nproduced by\",\n",
    "                            \"david reed\", \"\\ntypographical errors corrected\",\n",
    "                            \"\\[note: there is a\",\"etext editor's\",\"u.s. copyright\",\n",
    "                            \"\\nerrata\",\" ebook\",\" e-book\",\n",
    "                            \"author:     \",\"</pre>\", \"\\[end of\",\"internet archive\")\n",
    "                \n",
    "    \n",
    "    def clean_text(self,text):\n",
    "        text = text.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\") # normalize lines\n",
    "        text = re.sub(\"\\n[ *-]+\\n\",\"\\n\\n\",text) # get rid of explicit section breaks\n",
    "        #text = re.sub(\"\\[Illustration:?[^\\]]*\\]\",\"\",text)\n",
    "        text = re.sub(\"<<[^>]+>>\",\"\",text)\n",
    "        text = re.sub(\"[^_]_______________________________________.*_________________________________[^_]\",\"\\n\\n\",text)\n",
    "        lower_text = text.lower()\n",
    "        all_junk_indicies = [0, len(text)]\n",
    "        for junk_indicator in self.junk_indicators:\n",
    "            all_junk_indicies.extend([m.start() for m in re.finditer(junk_indicator,lower_text)])\n",
    "        all_junk_indicies.sort()\n",
    "        best_points = None\n",
    "        best_length = 0\n",
    "        for i in range(len(all_junk_indicies) - 1):\n",
    "            if all_junk_indicies[i+1] - all_junk_indicies[i] > best_length:\n",
    "                best_points = [all_junk_indicies[i],all_junk_indicies[i+1]]\n",
    "                best_length = all_junk_indicies[i+1] - all_junk_indicies[i]\n",
    "        found = False\n",
    "        best_length = float(best_length)\n",
    "        if best_length < 5000: # too small for general method to work reliably\n",
    "            m = re.search(\"end of [^\\\\n]*project gutenberg\",lower_text)\n",
    "            if m:\n",
    "                best_points[1] = m.start()\n",
    "                i = 0\n",
    "                while all_junk_indicies[i] < best_points[1] - 100:\n",
    "                    i += 1\n",
    "                best_points[0] = all_junk_indicies[i-1]\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        i = 4\n",
    "        while not found:\n",
    "            looking_for = \"\\n\"*i\n",
    "            result = text.find(looking_for, best_points[0])\n",
    "            if result != -1 and ((best_points[1] - result)/best_length > 0.98 or i == 1):\n",
    "                found = True\n",
    "            i -= 1\n",
    "\n",
    "        return text[result:text.rfind(\"\\n\", 0, best_points[1])].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process downloaded Gutenberg zip files.\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(...) as z:\n",
    "    with z.open(...) as f:\n",
    "        for line in f:\n",
    "            print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "MIN_SENTENCE_CHAR_LENGTH = 5  # \"I am.\" will qualify, but nothing shorter.\n",
    "\n",
    "def preprocess(text, CHUNK_CHAR_LENGTH=10000):\n",
    "    # Replace carraige return and tab characters.\n",
    "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n').replace('\\t', ' ')\n",
    "    print('1')\n",
    "    text = re.sub(\"[ ]*`\", \"'\", text)\n",
    "    print('2')\n",
    "    # Remove play character prompts like 'WALTER: ...'\n",
    "    text = re.sub('^[A-Z0-9\\'., ]+(?:\\([^)]*\\))?[:.][ ]*', '', text, flags=re.M)\n",
    "    print('3')\n",
    "    # Remove titles which are lines with all-caps.\n",
    "    text = re.sub('^[A-Z0-9.,-?$#!;:\\'\"_ ]+$', '', text, flags=re.M)\n",
    "    print('4')\n",
    "    # Remove divider lines like '* * * * *' and antiquated punctuation.\n",
    "    text = re.sub('^[ ]*[-*=_].*[-*=_][ ]*$', '', re.sub(':--', ':', re.sub('&c', 'etc', text)), flags=re.M)\n",
    "    print('5')\n",
    "    # Remove leading spaces, then remove all line breaks except for empty lines.\n",
    "    text = re.sub('\\n[^\\n]', ' ', re.sub('^[ ]+', '', text, flags=re.M))\n",
    "    print('6')\n",
    "    # Remove footnotes and references (can be nested one deep: [Note [Note in note]])\n",
    "    text = re.sub('\\[[^][]+\\]', '', re.sub('\\[[^][]+\\]', '', re.sub('^\\[[^ ]+\\] .*$', '', text, flags=re.M)))\n",
    "    print('7')\n",
    "    texts = []\n",
    "    remainder = text\n",
    "    N = len(remainder)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    while start < N:\n",
    "        end += CHUNK_CHAR_LENGTH\n",
    "        while end < N and remainder[end] != '\\n':\n",
    "            end += 1\n",
    "        # Remove all newlines, double spaces and underscores.\n",
    "        texts.append(\n",
    "            re.sub(' [ ]+', ' ', re.sub('\\n', ' ', remainder[start:end])).\n",
    "            replace('_', ''))\n",
    "        start = end\n",
    "    return texts\n",
    "\n",
    "def make_dataset(text):\n",
    "    print('processing text with spacy')\n",
    "    doc = nlp(text)\n",
    "    sents = list(doc.sents)\n",
    "    print('doc has {} sentences'.format(len(sents)))\n",
    "    data = []\n",
    "    for sent in sents:\n",
    "        if len(sent.text) < MIN_SENTENCE_CHAR_LENGTH:\n",
    "            continue\n",
    "        if len(data) % 20 == 0:\n",
    "            print('{}..'.format(len(data)), end='', flush=True)\n",
    "        data.append('< ' + sent.text)\n",
    "        data.append('> ' + transform_present_span(sent))\n",
    "    print('done')\n",
    "    return '\\n'.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "GUTENBERG_DIR = 'Gutenberg/txt'\n",
    "BIG_FILE = 'gutenberg.txt'\n",
    "OUTPUT_DIR = 'Gutenberg/out'\n",
    "\n",
    "def preprocess_multiple_texts():\n",
    "    i = 0\n",
    "    for fn in os.listdir(GUTENBERG_DIR):\n",
    "        if fn.endswith('.txt') and 'z2.txt' in fn:\n",
    "            with open(os.path.join(GUTENBERG_DIR, fn), 'r') as inf:\n",
    "                texts = preprocess(inf.read())\n",
    "                for j, text in enumerate(texts):\n",
    "                    with open(os.path.join(OUTPUT_DIR, f'{i}-{j}.txt'), 'w') as outf:\n",
    "                        outf.write(make_dataset(text))\n",
    "\n",
    "def preprocess_one_large_text(fn, chunk_size):\n",
    "    with open(os.path.join(GUTENBERG_DIR, fn), 'r') as inf:\n",
    "        texts = preprocess(inf.read(), chunk_size)\n",
    "        for j, text in enumerate(texts):\n",
    "            print(f'writing text {j}')\n",
    "            with open(os.path.join(OUTPUT_DIR, f'{j}.txt'), 'w') as outf:\n",
    "                outf.write(text)\n",
    "\n",
    "def process_one_large_text(fn, chunk_size):\n",
    "    with open(os.path.join(GUTENBERG_DIR, fn), 'r') as inf:\n",
    "        texts = preprocess(inf.read(), chunk_size)\n",
    "        for j, text in enumerate(texts):\n",
    "            print(f'writing text {j}')\n",
    "            with open(os.path.join(OUTPUT_DIR, f'{j}.txt'), 'w') as outf:\n",
    "                outf.write(make_dataset(text))\n",
    "\n",
    "def test_make_dataset_speed():\n",
    "    nlp('Warm up the parser.')\n",
    "    t1 = datetime.now()\n",
    "    process_one_large_text('test-30k.txt', 30000)\n",
    "    d = (datetime.now() - t1).seconds\n",
    "    print(f'30k: {d} seconds')\n",
    "    t1 = datetime.now()\n",
    "    process_one_large_text('test-30k.txt', 10000)\n",
    "    d = (datetime.now() - t1).seconds \n",
    "    print(f'3 x 10k: {d} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "writing text 0\n",
      "processing text with spacy\n",
      "doc has 390 sentences\n",
      "0..20..40..60..80..100..120..140..160..180..200..220..240..260..280..300..320..340..360..380..400..420..440..460..480..500..520..540..560..580..600..620..640..660..680..700..720..30k: 87 seconds\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "writing text 0\n",
      "processing text with spacy\n",
      "doc has 119 sentences\n",
      "0..20..40..60..80..100..120..140..160..180..200..220..writing text 1\n",
      "processing text with spacy\n",
      "doc has 168 sentences\n",
      "0..20..40..60..80..100..120..140..160..180..200..220..240..260..280..300..writing text 2\n",
      "processing text with spacy\n",
      "doc has 103 sentences\n",
      "0..20..40..60..80..100..120..140..160..180..3 x 10k: 89 seconds\n"
     ]
    }
   ],
   "source": [
    "test_make_dataset_speed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
